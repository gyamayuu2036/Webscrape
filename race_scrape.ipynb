{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTables(response):\n",
    "    # HTTPステータスコードが200（成功）の場合のみ処理を続行\n",
    "    if response.getcode() == 200:\n",
    "        # HTMLをパースしてBeautifulSoupオブジェクトを作成\n",
    "        bs = BeautifulSoup(response, 'html.parser')\n",
    "        bs = bs.decode('UTF-8')\n",
    "        html_string = str(bs)\n",
    "        html_io = StringIO(html_string)\n",
    "\n",
    "        # テーブルデータを抽出\n",
    "        tables = pd.read_html(html_io)\n",
    "        df = tables[0]\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(f\"HTTPステータスコード {response.getcode()}: ページの取得に失敗しました\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#開催年\n",
    "years = [str(i).zfill(4) for i in range(2021, 2022)]\n",
    "#開催場所 01:札幌, 02:函館, 03:福島, 04:新潟, 05:東京, 06:中山, 07:中京, 08:京都, 09::阪神, 10:小倉\n",
    "places = [str(i).zfill(2) for i in range (5, 6)]\n",
    "#開催回\n",
    "times = [str(i).zfill(2) for i in range(1, 2)]\n",
    "#開催日\n",
    "days = [str(i).zfill(2) for i in range(1, 2)]\n",
    "#レースNo\n",
    "races = [str(i).zfill(2) for i in range(1, 13)]\n",
    "\n",
    "raceIdList = []\n",
    "for y in years:\n",
    "    for p in places:\n",
    "        for t in times:\n",
    "            for d in days:\n",
    "                for r in races:\n",
    "                    raceIdList.append(y + p + t + d + r)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://db.netkeiba.com/race/'\n",
    "colName = ['raceId', 'htmlBytes']\n",
    "df = pd.DataFrame(columns=colName)\n",
    "escapeList = []\n",
    "\n",
    "# pickleファイルが存在するか確認し、データを読み込む\n",
    "if os.path.isfile('race_html.pkl'):\n",
    "    df = pd.read_pickle('race_html.pkl')\n",
    "    escapeList = df['raceId'].to_list()\n",
    "\n",
    "# ページネーション用の競走IDリストを生成する関数\n",
    "def addEscapeList(id: str, ll: list):\n",
    "    idAry = [id[0:4], id[4:6], id[6:8], id[8:10], id[10:12]]\n",
    "    for r in range(1, 13):\n",
    "        idAry[4] = str(r).zfill(2)\n",
    "        ll.append(''.join(idAry))\n",
    "    if idAry[3] == '01':\n",
    "        for d in range(2, 9):\n",
    "            idAry[3] = str(d).zfill(2)\n",
    "            ll = addEscapeList(''.join(idAry), ll)\n",
    "    if idAry[2] == '01':\n",
    "        for t in range(2, 9):\n",
    "            idAry[2] = str(t).zfill(2)\n",
    "            ll = addEscapeList(''.join(idAry), ll)\n",
    "\n",
    "    return ll\n",
    "\n",
    "# raceIdListに実際の競走IDのリストがあると仮定します\n",
    "# raceIdList = ...\n",
    "\n",
    "for raceId in tqdm(raceIdList):\n",
    "    try:\n",
    "        if raceId in escapeList:\n",
    "            continue\n",
    "        response = url + raceId\n",
    "        html = requests.get(response)\n",
    "        #html.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "\n",
    "        if 'レース結果' in soup.text:\n",
    "            tmpDf = pd.DataFrame([[raceId, html.content]], columns=colName)  # 'colmuns'の誤りを修正\n",
    "            df = pd.concat([df, tmpDf], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            escapeList = addEscapeList(raceId, escapeList)  # 変数名を修正\n",
    "\n",
    "        time.sleep(3)\n",
    "    except Exception as e:  # 例外をキャッチしてログに記録\n",
    "        print(f'例外が発生しました: {str(e)}')\n",
    "\n",
    "# DataFrameをpickleファイルに保存\n",
    "df.to_pickle('race_html.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlDf = pd.read_pickel('race_html.pkl')\n",
    "raceResultDf = pd.DataFrame()\n",
    "raceId =''\n",
    "htmlBytes = b''\n",
    "for idx, dat in tqdm(htmlDf.iterrows(), total=len(htmlDf)):\n",
    "    raceId = dat['raceId']\n",
    "    htmlBytes = dat['htmlBytes']\n",
    "\n",
    "    soup = BeautifulSoup(htmlBytes, 'htmlParser')\n",
    "    table = soup.fin_all('table')[0]\n",
    "\n",
    "    columns = []\n",
    "\n",
    "    for head in table.find_all('th'):\n",
    "        columns.append(head.text)\n",
    "\n",
    "    columns = ['raceId'] + columns + ['horseId', 'jockeyId', 'trainerId']\n",
    "    df = pd.Dataframe(columns=columns)\n",
    "\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        items = [raceId]\n",
    "\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        for cell in cells:\n",
    "            items.append(cell.text.replace('\\n',''))\n",
    "\n",
    "        items.append(str(cells[3])split('/horse/')[1].split('/')[0])\n",
    "        items.append(str(cells[6]).split('/recent/')[1].split('/')[0])\n",
    "        items.append(str(cells[18]).split('/recent')[1].split('/')[0])\n",
    "\n",
    "        df.loc[i] = items\n",
    "    break\n",
    "\n",
    "raceResultDf = pd.concat([raceResultDf, df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv',encoding='utf-8')\n",
    "df.columns\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
